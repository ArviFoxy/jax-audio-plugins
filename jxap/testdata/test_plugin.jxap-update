#loc = loc(unknown)
#loc11 = loc("state[0]")
#loc12 = loc("buffers['input']")
module @jit__update_fn attributes {jax.uses_shape_polymorphism = true, mhlo.num_partitions = 1 : i32, mhlo.num_replicas = 1 : i32} {
  func.func public @main(%arg0: tensor<i32> {jax.global_constant = "_platform_index"} loc(unknown), %arg1: tensor<?xf32> loc(unknown), %arg2: tensor<?x?xf32> loc(unknown)) -> (tensor<?xf32> {jax.result_info = "result[0][0]"}, tensor<?x?xf32> {jax.result_info = "result[1]['output']"}) {
    %c = stablehlo.constant dense<0> : tensor<i32> loc(#loc)
    %c_0 = stablehlo.constant dense<-1> : tensor<i32> loc(#loc)
    %c_1 = stablehlo.constant dense<1> : tensor<i32> loc(#loc)
    %0 = stablehlo.get_dimension_size %arg1, dim = 0 : (tensor<?xf32>) -> tensor<i32> loc(#loc57)
    %1 = stablehlo.get_dimension_size %arg2, dim = 0 : (tensor<?x?xf32>) -> tensor<i32> loc(#loc57)
    %2 = stablehlo.get_dimension_size %arg2, dim = 1 : (tensor<?x?xf32>) -> tensor<i32> loc(#loc57)
    %3 = stablehlo.compare  GE, %0, %c_1,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1> loc(#loc58)
    stablehlo.custom_call @shape_assertion(%3, %0) {api_version = 2 : i32, error_message = "Input shapes do not match the polymorphic shapes specification. Expected value >= 1 for dimension variable 'NumChannels0'. Using the following polymorphic shapes specifications: args[0][0].shape = (NumChannels0,),args[1]['input'].shape = (BufferSize, NumChannels0). Obtained dimension variables: 'NumChannels0' = {0} from specification 'NumChannels0' for dimension args[0][0].shape[0] (= {0}), . Please see https://docs.jax.dev/en/latest/export/shape_poly.html#shape-assertion-errors for more details.", has_side_effect = true} : (tensor<i1>, tensor<i32>) -> () loc(#loc59)
    %4 = stablehlo.compare  GE, %1, %c_1,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1> loc(#loc58)
    stablehlo.custom_call @shape_assertion(%4, %0, %1) {api_version = 2 : i32, error_message = "Input shapes do not match the polymorphic shapes specification. Expected value >= 1 for dimension variable 'BufferSize'. Using the following polymorphic shapes specifications: args[0][0].shape = (NumChannels0,),args[1]['input'].shape = (BufferSize, NumChannels0). Obtained dimension variables: 'NumChannels0' = {0} from specification 'NumChannels0' for dimension args[0][0].shape[0] (= {0}), 'BufferSize' = {1} from specification 'BufferSize' for dimension args[1]['input'].shape[0] (= {1}), . Please see https://docs.jax.dev/en/latest/export/shape_poly.html#shape-assertion-errors for more details.", has_side_effect = true} : (tensor<i1>, tensor<i32>, tensor<i32>) -> () loc(#loc59)
    %5 = stablehlo.compare  EQ, %2, %0,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1> loc(#loc60)
    stablehlo.custom_call @shape_assertion(%5, %2, %0, %1) {api_version = 2 : i32, error_message = "Input shapes do not match the polymorphic shapes specification. Found inconsistency between dimension size args[1]['input'].shape[1] (= {0}) and the specification 'NumChannels0' (= {1}). Using the following polymorphic shapes specifications: args[0][0].shape = (NumChannels0,),args[1]['input'].shape = (BufferSize, NumChannels0). Obtained dimension variables: 'NumChannels0' = {1} from specification 'NumChannels0' for dimension args[0][0].shape[0] (= {1}), 'BufferSize' = {2} from specification 'BufferSize' for dimension args[1]['input'].shape[0] (= {2}), . Please see https://docs.jax.dev/en/latest/export/shape_poly.html#shape-assertion-errors for more details.", has_side_effect = true} : (tensor<i1>, tensor<i32>, tensor<i32>, tensor<i32>) -> () loc(#loc59)
    %6 = stablehlo.convert %1 : tensor<i32> loc(#loc61)
    %7 = stablehlo.add %6, %c_0 : tensor<i32> loc(#loc62)
    %8 = stablehlo.compare  GE, %7, %c,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1> loc(#loc58)
    %9 = stablehlo.convert %1 : tensor<i32> loc(#loc61)
    %10 = stablehlo.add %9, %c_0 : tensor<i32> loc(#loc62)
    stablehlo.custom_call @shape_assertion(%8, %10, %0, %1) {api_version = 2 : i32, error_message = "Input shapes do not match the symbolic shape constraint BufferSize >= 1. Expected 'BufferSize - 1' to be greater or equal to 0, but found {0}.  Using the following polymorphic shapes specifications: args[0][0].shape = (NumChannels0,),args[1]['input'].shape = (BufferSize, NumChannels0). Obtained dimension variables: 'NumChannels0' = {1} from specification 'NumChannels0' for dimension args[0][0].shape[0] (= {1}), 'BufferSize' = {2} from specification 'BufferSize' for dimension args[1]['input'].shape[0] (= {2}), . Please see https://docs.jax.dev/en/latest/export/shape_poly.html#shape-assertion-errors for more details.", has_side_effect = true} : (tensor<i1>, tensor<i32>, tensor<i32>, tensor<i32>) -> () loc(#loc59)
    %11 = stablehlo.convert %0 : tensor<i32> loc(#loc61)
    %12 = stablehlo.add %11, %c_0 : tensor<i32> loc(#loc62)
    %13 = stablehlo.compare  GE, %12, %c,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1> loc(#loc58)
    %14 = stablehlo.convert %0 : tensor<i32> loc(#loc61)
    %15 = stablehlo.add %14, %c_0 : tensor<i32> loc(#loc62)
    stablehlo.custom_call @shape_assertion(%13, %15, %0, %1) {api_version = 2 : i32, error_message = "Input shapes do not match the symbolic shape constraint NumChannels0 >= 1. Expected 'NumChannels0 - 1' to be greater or equal to 0, but found {0}.  Using the following polymorphic shapes specifications: args[0][0].shape = (NumChannels0,),args[1]['input'].shape = (BufferSize, NumChannels0). Obtained dimension variables: 'NumChannels0' = {1} from specification 'NumChannels0' for dimension args[0][0].shape[0] (= {1}), 'BufferSize' = {2} from specification 'BufferSize' for dimension args[1]['input'].shape[0] (= {2}), . Please see https://docs.jax.dev/en/latest/export/shape_poly.html#shape-assertion-errors for more details.", has_side_effect = true} : (tensor<i1>, tensor<i32>, tensor<i32>, tensor<i32>) -> () loc(#loc59)
    %16:2 = call @_wrapped_jax_export_main(%arg0, %1, %0, %arg1, %arg2) : (tensor<i32>, tensor<i32>, tensor<i32>, tensor<?xf32>, tensor<?x?xf32>) -> (tensor<?xf32>, tensor<?x?xf32>) loc(#loc)
    return %16#0, %16#1 : tensor<?xf32>, tensor<?x?xf32> loc(#loc)
  } loc(#loc)
  func.func private @_wrapped_jax_export_main(%arg0: tensor<i32> {jax.global_constant = "_platform_index"} loc(unknown), %arg1: tensor<i32> {jax.global_constant = "BufferSize"} loc(unknown), %arg2: tensor<i32> {jax.global_constant = "NumChannels0"} loc(unknown), %arg3: tensor<?xf32> loc("state[0]"), %arg4: tensor<?x?xf32> loc("buffers['input']")) -> (tensor<?xf32> {jax.result_info = "result[0][0]"}, tensor<?x?xf32> {jax.result_info = "result[1]['output']"}) {
    %c = stablehlo.constant dense<0> : tensor<i32> loc(#loc)
    %c_0 = stablehlo.constant dense<1> : tensor<1xi32> loc(#loc)
    %c_1 = stablehlo.constant dense<-1> : tensor<i32> loc(#loc)
    %c_2 = stablehlo.constant dense<1> : tensor<i32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<i32>) -> tensor<1xi32> loc(#loc63)
    %1 = stablehlo.convert %arg1 : tensor<i32> loc(#loc64)
    %2 = stablehlo.add %1, %c_1 : tensor<i32> loc(#loc65)
    %3 = stablehlo.reshape %2 : (tensor<i32>) -> tensor<1xi32> loc(#loc66)
    %4 = stablehlo.reshape %arg2 : (tensor<i32>) -> tensor<1xi32> loc(#loc66)
    %5 = stablehlo.concatenate %3, %4, dim = 0 : (tensor<1xi32>, tensor<1xi32>) -> tensor<2xi32> loc(#loc66)
    %6 = "stablehlo.dynamic_gather"(%arg4, %0, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1], start_index_map = [0]>, indices_are_sorted = true}> : (tensor<?x?xf32>, tensor<1xi32>, tensor<2xi32>) -> tensor<?x?xf32> loc(#loc66)
    %7 = stablehlo.reshape %arg2 : (tensor<i32>) -> tensor<1xi32> loc(#loc67)
    %8 = stablehlo.concatenate %c_0, %7, dim = 0 : (tensor<1xi32>, tensor<1xi32>) -> tensor<2xi32> loc(#loc67)
    %9 = stablehlo.dynamic_broadcast_in_dim %arg3, %8, dims = [1] : (tensor<?xf32>, tensor<2xi32>) -> tensor<1x?xf32> loc(#loc67)
    %10 = stablehlo.concatenate %6, %9, dim = 0 : (tensor<?x?xf32>, tensor<1x?xf32>) -> tensor<?x?xf32> loc(#loc68)
    %11 = stablehlo.add %arg4, %10 : tensor<?x?xf32> loc(#loc69)
    %12 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i32>) -> tensor<1xi32> loc(#loc70)
    %13 = stablehlo.reshape %arg2 : (tensor<i32>) -> tensor<1xi32> loc(#loc71)
    %14 = stablehlo.concatenate %c_0, %13, dim = 0 : (tensor<1xi32>, tensor<1xi32>) -> tensor<2xi32> loc(#loc71)
    %15 = "stablehlo.dynamic_gather"(%arg4, %12, %14) <{dimension_numbers = #stablehlo.gather<offset_dims = [0], collapsed_slice_dims = [0], start_index_map = [0]>, indices_are_sorted = true}> : (tensor<?x?xf32>, tensor<1xi32>, tensor<2xi32>) -> tensor<?xf32> loc(#loc71)
    return %15, %11 : tensor<?xf32>, tensor<?x?xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc1 = loc("/workspaces/jax-audio-plugins/python/jax_audio_plugins/export.py":117:25 to 118:69)
#loc2 = loc("/workspaces/jax-audio-plugins/python/jax_audio_plugins/export_test.py":47:8 to :49)
#loc3 = loc("/workspaces/.venv/lib/python3.11/site-packages/absl/testing/_pretty_print_reporter.py":84:13 to :30)
#loc4 = loc("/workspaces/.venv/lib/python3.11/site-packages/absl/testing/absltest.py":2793:19 to :56)
#loc5 = loc("/workspaces/.venv/lib/python3.11/site-packages/absl/testing/absltest.py":2829:35 to 2831:3)
#loc6 = loc("/workspaces/.venv/lib/python3.11/site-packages/absl/testing/absltest.py":2373:6 to :34)
#loc7 = loc("/workspaces/.venv/lib/python3.11/site-packages/absl/app.py":261:13 to :23)
#loc8 = loc("/workspaces/.venv/lib/python3.11/site-packages/absl/app.py":316:6 to :27)
#loc9 = loc("/workspaces/.venv/lib/python3.11/site-packages/absl/testing/absltest.py":2375:4 to :31)
#loc10 = loc("/workspaces/.venv/lib/python3.11/site-packages/absl/testing/absltest.py":2269:2 to :38)
#loc13 = loc("/workspaces/jax-audio-plugins/python/jax_audio_plugins/export_test.py":36:31 to :36)
#loc14 = loc("/workspaces/jax-audio-plugins/python/jax_audio_plugins/export.py":111:29 to :58)
#loc15 = loc("/workspaces/jax-audio-plugins/python/jax_audio_plugins/export_test.py":36:38 to :68)
#loc16 = loc("/workspaces/jax-audio-plugins/python/jax_audio_plugins/export_test.py":36:14 to :78)
#loc17 = loc("/workspaces/jax-audio-plugins/python/jax_audio_plugins/export_test.py":37:12 to :19)
#loc18 = loc("/workspaces/jax-audio-plugins/python/jax_audio_plugins/export_test.py":38:48 to :52)
#loc19 = loc("export_plugin"(#loc1))
#loc20 = loc("ExportingTest.test_export_plugin"(#loc2))
#loc21 = loc("TextTestRunner.run"(#loc3))
#loc22 = loc("_run_and_get_tests_result"(#loc4))
#loc23 = loc("run_tests"(#loc5))
#loc24 = loc("_run_in_app.<locals>.main_function"(#loc6))
#loc25 = loc("_run_main"(#loc7))
#loc26 = loc("run"(#loc8))
#loc27 = loc("_run_in_app"(#loc9))
#loc28 = loc("main"(#loc10))
#loc29 = loc("TestPlugin.update"(#loc13))
#loc30 = loc("export_plugin.<locals>._update_fn"(#loc14))
#loc31 = loc("TestPlugin.update"(#loc15))
#loc32 = loc("TestPlugin.update"(#loc16))
#loc33 = loc("TestPlugin.update"(#loc17))
#loc34 = loc("TestPlugin.update"(#loc18))
#loc35 = loc(callsite(#loc27 at #loc28))
#loc36 = loc(callsite(#loc25 at #loc26))
#loc37 = loc(callsite(#loc26 at #loc35))
#loc38 = loc(callsite(#loc24 at #loc36))
#loc39 = loc(callsite(#loc25 at #loc37))
#loc40 = loc(callsite(#loc23 at #loc38))
#loc41 = loc(callsite(#loc24 at #loc39))
#loc42 = loc(callsite(#loc22 at #loc40))
#loc43 = loc(callsite(#loc23 at #loc41))
#loc44 = loc(callsite(#loc21 at #loc42))
#loc45 = loc(callsite(#loc22 at #loc43))
#loc46 = loc(callsite(#loc20 at #loc44))
#loc47 = loc(callsite(#loc21 at #loc45))
#loc48 = loc(callsite(#loc19 at #loc46))
#loc49 = loc(callsite(#loc20 at #loc47))
#loc50 = loc(callsite(#loc30 at #loc48))
#loc51 = loc(callsite(#loc19 at #loc49))
#loc52 = loc(callsite(#loc29 at #loc50))
#loc53 = loc(callsite(#loc31 at #loc50))
#loc54 = loc(callsite(#loc32 at #loc50))
#loc55 = loc(callsite(#loc33 at #loc50))
#loc56 = loc(callsite(#loc34 at #loc50))
#loc57 = loc("/dimension_size"(#loc51))
#loc58 = loc("/ge"(#loc51))
#loc59 = loc("/shape_assertion"(#loc51))
#loc60 = loc("/eq"(#loc51))
#loc61 = loc("/convert_element_type"(#loc51))
#loc62 = loc("/add"(#loc51))
#loc63 = loc("jit(_update_fn)/jit(main)/broadcast_in_dim"(#loc52))
#loc64 = loc("jit(_update_fn)/jit(main)/convert_element_type"(#loc52))
#loc65 = loc("jit(_update_fn)/jit(main)/add"(#loc52))
#loc66 = loc("jit(_update_fn)/jit(main)/gather"(#loc52))
#loc67 = loc("jit(_update_fn)/jit(main)/broadcast_in_dim"(#loc53))
#loc68 = loc("jit(_update_fn)/jit(main)/concatenate"(#loc54))
#loc69 = loc("jit(_update_fn)/jit(main)/add"(#loc55))
#loc70 = loc("jit(_update_fn)/jit(main)/broadcast_in_dim"(#loc56))
#loc71 = loc("jit(_update_fn)/jit(main)/gather"(#loc56))
